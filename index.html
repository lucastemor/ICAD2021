<!DOCTYPE html><html>  <head>    <meta http-equiv="content-type" content="text/html; charset=UTF-8">    <link rel="stylesheet" href="css/modal.css">    <title>BSL ICAD 2021</title>  </head>  <style>    body{      width:  75%;      margin: 0 auto;      margin-top: 25px;    }    h1 {      text-align: center;    }    table {      table-layout: fixed;    }    .section{      background-color: #e6ffe6;      border: 2px solid #b3ffb3;      border-radius: 25px;    }    .content-table{      border-collapse: collapse;    }    .section-content-table-data{    }    .name {      text-align: center;    }    .section-heading{     text-align: center;     font-size:  30px;     }    li:not(:last-child) {    margin-bottom: 10px;    }    area:hover{      background-color: gray;    }    img{      cursor: pointer;    }  .vid:hover{    opacity: 0.7;    background-color: F6F6F6;  }  </style>  <body>    <div class="section">      <h1>Perceptually-motivated sonification</h1> <h1>of spatiotemporally-dynamic CFD data</h1>            <table style="width:100%">        <tr>          <th class ="name">Lucas Temor<sup>1</sup></th>          <th class ="name">Daniel E. Macdonald<sup>1</sup></th>           <th class ="name">Thangam Natarajan<sup>1</sup></th>          <th class ="name">Peter W. Coppin<sup>2</sup></th>          <th class ="name">David A. Steinman<sup>1</sup></th>        </tr>      </table>      <table style="width:100%">        <tr>          <td class ="name"><sup>1</sup><a href = "https://bsl.mie.utoronto.ca", target="_blank">Biomedical Simulation Lab, University of Toronto, Toronto, Canada</a></td>          <td class ="name"><sup>2</sup>Perceptual Artifacts Lab, OCAD University, Toronto, Canada</td>        </tr>      </table>    </div>           <br><br>    <div class="section">        <table class="content-table" style="width:100%">          <tr class="main-content-table-row">            <th class ="section-heading">Introduction</th>          </tr>          <!--- INTRODUCTION -->          <tr class="main-content-table-row">            <td class="section-content-table-data" valign="top">              <ul>                <li>The visualization of multidimensional spatiotemporal data presents a challenging representational problem that often overlooks the strengths of the multiple sensory channels of the human perceptual system</li>                <li>Our interest in this area stems from our research into the use of computational fluid dynamics (CFD) for predicting cerebral aneurysm rupture </li>                <li>We aim to use sonification to better understand the nature of turbulent-like instabilities in our data which may have clinical relevance</li>                <li>Previous word has focused on developing algorithms and aesthetics but did not heavily consider how the resultant sounds were being interpreted to make sense of these complex flows</li>              </ul>              <h3 align="center">Previous work</h3>              <p align="center">                  <img class="myBtn_multi vid" src="media/richard-graphic.png" alt="2017 video sonification" width=15%>                  <img class="myBtn_multi vid" src="media/dan-graphic.png" alt="2018 spectral sonification" width=15%>              </p>                <div class="modal modal_multi">                    <div class="modal-content">                        <span class="close close_multi">×</span>                        <h2>2017 - Video sonification</h2>                        <p>Video sonification was too dependent on subjective rendering choices such as camera positions</p>                        <br>                        <p align="center"> <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/uifvp1S-WKU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                    </div>                </div>                <div class="modal modal_multi">                    <div class="modal-content">                        <span class="close close_multi">×</span>                        <h2>2018 - Spectral sonification</h2>                        <p>Using this technique it was difficult to pick out certain features in the data such as the presence of spectral harmonics. There was also insufficient temporal variation present in the sounds to communicate the presence of quasi-random fluctuations in the flow. Sounds were too similar within and/or betwen models.</p>                        <br>                        <p align="center"><iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/UmDvnPjnpV4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                    </div>                </div>            </td>        </table>    </div>    <br><br>    <div class="section">        <table class="content-table" style="width:100%">          <tr class="main-content-table-row">            <th class ="section-heading" style="border-radius: 25px; border-right: 2px solid #b3ffb3;">Methods</th>             <th class ="section-heading">Results</th>          </tr>            <!---  METHODS -->                    <td class="section-content-table-data" valign="top" style="border-right: 2px solid #b3ffb3; border-radius: 25px;">              <ul>                <li>The figure below is interactive</li>                <li>We took a feature based approach, informed by ideas from auditory scene analysis and the idea of "caricature"</li>                <li>Spectral features and motion from 2D Q-criterion projections are sonified using timbrally distinct instrument models</li>              </ul>              <p align="center"><img src="media/figure3-transparant.png" alt="Methods" usemap="#methodsmap" border=0 width="100%" height="auto" class="map"></p>                  <map name="methodsmap" id=Map>                  <area class="myBtn_multi" target="" alt="cfd-data" title="cfd-data" href="#" coords="68,1080,884,172" shape="rect">                  <area class="myBtn_multi" target="" alt="harmonics" title="harmonics" href="#" coords="1040,108,1453,465" shape="rect">                  <area class="myBtn_multi" target="" alt="envelope" title="envelope" href="#" coords="1467,475,1038,805" shape="rect">                  <area class="myBtn_multi" target="" alt="projection" title="projection" href="#" coords="1020,814,1495,1098" shape="rect">                  <area class="myBtn_multi" target="" alt="tonal" title="tonal" href="#" coords="2020,541,1587,172" shape="rect">                  <area class="myBtn_multi" target="" alt="buffeting" title="buffeting" href="#" coords="2022,611,1575,1088" shape="rect">                  <area class="myBtn_multi" target="" alt="output" title="output" href="#" coords="2048,441,2266,695" shape="rect">              </map>              <!-- CFD DATA MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>CFD data</h2>                      <p>We begin by computing the average spectrogram and Q-criterion in an aneurysm sac. The spectrogram acts as a sort of "global" indicator of flow instability, and the Q-criterion communicates more localized spatiotemporal fluctuations.                      <p align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/BmHwz3CB3TI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                  </div>              </div>              <!-- HARMONIC FEATURES MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>Spectral harmonics feature</h2>                      <p>Spectral harmonics can be extracted by finding local maxima in column-wise traces of power alone the spectrogram's time axis. These bands are extracted and labelled depending on their temporal occurrence such that simultaneous harmonics are grouped together.</p>                      <p align="center"><img src="media/harmonics.gif" width=50% height="auto"></p>                  </div>              </div>              <!-- ENVELOPE FEATURES MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>Spectral envelope feature</h2>                      <p>The envelope feature is extracted by finding the largest non-zero frequency bin at each time point.</p>                      <p align="center"><img src="media/envelope.gif" width=50% height="auto"></p>                  </div>              </div>                                                 <!-- PROJECTION MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>2D Motion projection</h2>                      <p>The aneurysm sac and its Q-criterion isosurfaces are flattened in the direction normal to the aneurysm's ostium.</p>                      <p align="center"> <img src="media/squish.gif" width=70% height=auto></p>                      <p>The strength and location of vortical structures are approximated by casting out 16 rays spaced at equal angles from the flattened plante's centre. The average magnitude of Q-criterion and the location of the center of intersecting structures is retained.</p>                      <p align="center"> <img src="media/flatmotion.gif" width=70% height=auto></p>                  </div>              </div>              <!-- TONAL INSTRUMENT MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>Tonal instrument</h2>                      <p>An overtone rich sawtooth synth is used to sonify each harmonic band such that vertically stacked bands will form the sounds of major chords.</p>                      <p>Listen to the isolated instrument below</p>                      <p align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/aGSSuubsGU4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                  </div>              </div>              <!-- BUFFETING INSTRUMENT MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>FM synthesis instrument model</h2>                      <p>The strength of vortical structures and their distance to the centre of the sac are used to modulate a noisy synth model that is designed to bear sound-source similarity to turbulent fluids, changing in its "buffeting" rate as more rapidly fluctuating structures are passed into it. The spectral envelope is added, proportionally controlling the cutoff of a additional instrument model. </p>                      <p align="center"> <img src="media/figure6.png" width=50% height=auto></p>                      <br>                      <p>Listen to the isolated instrument below</p>                      <p align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/1IBbFwinW5I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                      <br><br><br><br><br><br><br>                  </div>              </div>              <!-- OUTPUT AUDIO MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>Output visualization with sonification</h2>                      <p>The tonal and buffeting sounds are mixed together and syncronized with their corresponding visualization.</p>                      <p align="center"><iframe  class="yt" width="560" height="315" src="https://www.youtube.com/embed/Lq1EBxjr2GI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                  </div>              </div>            </td>            <!--- RESULTS -->                    <td class="section-content-table-data" valign=top>              <ul>                <li>In general, the current sonification allows for classification of flow phenotypes with respect to the detection of broadband and harmonic spectral features, as well as improved identification of finer-scale spatiotemporal fluctuations in the data, offering a noticeable improvement when compared to previous prototypes.</li>              </ul>              <p align="center"><img class="myBtn_multi vid" src="media/results_pic.png" alt="Results" width=80%></p>                <div class="modal modal_multi">                    <div class="modal-content">                        <span class="close close_multi">×</span>                        <h2>Results</h2>                        <br>                        <p>The new sonifiations allow for better distinctions to be made between flow patterns. The videos and text below will walk through the different classifications that can be made using these sonifications. </p>                        <table>                          <tr>                            <th>"Laminiar" vs. "Unstable" flow</th>                          </tr>                          <tr>                            <td>Comparing the global evolution of a flow's sonic characteristics allows for this classification to be made with relative ease based on everyday listening experiences. Laminar flows will sound like a quick pulse with no noisy components. This is contrasted with "turbulent" flows which here are synthesized to sound more noisy and buffeting. </td>                          </tr>                          <tr>                            <td>                              <p align="center"><iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/YMyc3xbVkws" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                              <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/Lq1EBxjr2GI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </p>                                                        </td>                          </tr>                          <tr>                            <th>"Chaotic turbulence" vs. "Vortex shedding" </th>                          </tr>                          <tr>                            <td>Detecting the presence of harmonic featres in the sonifications can help the listener to identify whether instabilities in the flow visualizations are a result of pure "turbulence" or a more "periodic vortex shedding". The "chaotic turbulence" case on the left does not present any harmonic structures whereas the case on the right does (listen for the whistling sound present in the second case that is not identifiable in the first). We can see that visually, the vortical structures in the first case appear to be far less coherent than those in the second where we can sonically detect these harmonic structures, reinforcing that the coherent structures being shed just past the aneirysm's neck are the result of a periodic vortex shedding phenomenon.</td>                          </tr>                          <tr>                            <td>                              <p align="center">                                  <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/1NpMiylOZ8I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                                  <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/Lq1EBxjr2GI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                              </p>                                                        </td>                          </tr>                                                    <th>Differences in quasi-random fluctuations</th>                          </tr>                          <tr>                            <td>The spectrograms for either case below are quite similar with respect to their envelope and harmonic features. Either case, however, seems to have quite different flow patterns which is here reflected through differences in the fluctuating sounds generated from either case. In the case on the left, we see a major large core form in the centre of the sac which appears to fluctuate and rotate in place. On the left, as has been mentioned, we see coherent structures being shed from around the neck of the aneurysm. These differences in motion are sonically captured by the buffeting sounds generated in either case. In the first case, the periodicity of the buffeting sound seems to sync with the periodicity of the central core's rotation/fluctuation. In the second case, the periodicity of the buffeting sound seems to sync with the frequency of the shed vortices.</td>                          </tr>                          <tr>                            <td>                              <p align="center">                                                                    <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/lWqGOzN7Lio" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                                  <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/Lq1EBxjr2GI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                              </p>                                                        </td>                          </tr>                            </table>                        <br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>                    </div>                </div>            </td>          </tr>        </table>    </div>    <br><br>    <div class="section">        <table class="content-table" style="width:100%">          <tr class="main-content-table-row">            <th class ="section-heading" style="border-right: 2px solid #b3ffb3; border-radius: 25px;">Discussion</th>            <th class ="section-heading">Conclusion</th>           </tr>          <tr>            <td class="section-content-table-data" valign="top" style="border-right: 2px solid #b3ffb3; border-radius: 25px;">              <ul>                <li>Our "carictured" approach allows for characteristic features to be interpreted quickly, while minimizing those features that are common between models</li>                <li>There seems to be a redundancy gain when congruency is maintained between visualizations and sonifications</li>                <li>The apparant timbral differences allow for the "schema based" scene analysis system to perceptually segregate different features</li>                <li>Sound-source instrument models allow for quick interpretation of the behavior otf "turbulence" and the presence and persistence of harmonics, which we hypothesize to be occuring because of resonant phenomena in aneurysms</li>              </ul>            </td>            <td class="section-content-table-data" valign="top">              <ul>                <li>Sounds must be validated in user studies</li>                <li>There is existing clinical intuition for working with sound</li>              </ul>            </td>          </tr>        </table>  </div>  <br>  <p align="center"><a href="mailto:lucas.temor@mail.utoronto.ca"><img class="vid" src="media/email.png" width="5%" height="auto"></p></a>  <br><br><br><br><br><br><br><br>    <script>      window.addEventListener('resize', function () {           "use strict";          window.location.reload();       });    </script>          <script src="js/modal.js"></script>    <script type="text/javascript" src="https://code.jquery.com/jquery-3.3.1.min.js"></script>    <script type="text/javascript" src="js/maphilight-master/jquery.maphilight.min.js"></script>    <script type="text/javascript" src="js/image-map-resizer-master/js/imageMapResizer.min.js"></script>    <script type="text/javascript">$(function() {        $('.map').maphilight();         });    </script>    <script type="text/javascript">    $('map').imageMapResize();    </script>    <script>      $('map').click(function(event)      {        event.preventDefault();      });    </script>  </body></html>