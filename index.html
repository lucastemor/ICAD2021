<!DOCTYPE html><html>  <head>    <meta http-equiv="content-type" content="text/html; charset=UTF-8">    <link rel="stylesheet" href="css/modal.css">    <title>BSL ICAD 2021</title>  </head>  <style>    body{      width:  75%;      margin: 0 auto;      margin-top: 25px;    }    h1 {      text-align: center;    }    table {      table-layout: fixed;    }    .section{      background-color:   #ffe6e6;      border: 3px solid #ff8080;;      border-radius: 25px;      box-shadow:  5px 5px 5px gray;    }    .content-table{      border-collapse: collapse;    }    .section-content-table-data{    }    .name {      text-align: center;    }    .section-heading{     text-align: center;     font-size:  30px;     }    li:not(:last-child) {    margin-bottom: 10px;    }    area:hover{      background-color: gray;    }    img{      cursor: pointer;    }  .vid:hover{    opacity: 0.7;    background-color: F6F6F6;    box-shadow: 10px 10px 10px gray;    border-radius: 5%;  }  .vid{   box-shadow: 5px 5px 5px gray;    border-radius: 5%;  }  body{    font-family: 'Arial', sans-serif;}  </style>  <body>    <div class="section">      <h1>Perceptually-motivated sonification</h1> <h1>of spatiotemporally-dynamic CFD data</h1>            <table style="width:100%">        <tr>          <th class ="name">Lucas Temor<sup>1</sup></th>          <th class ="name">Daniel E. MacDonald<sup>1</sup></th>           <th class ="name">Thangam Natarajan<sup>1</sup></th>          <th class ="name">Peter W. Coppin<sup>2</sup></th>          <th class ="name">David A. Steinman<sup>1</sup></th>        </tr>      </table>      <table style="width:100%">        <tr>          <td class ="name"><sup>1</sup><a href = "https://bsl.mie.utoronto.ca", target="_blank">Biomedical Simulation Lab, University of Toronto, Toronto, Canada</a></td>          <td class ="name"><sup>2</sup>Perceptual Artifacts Lab, OCAD University, Toronto, Canada</td>        </tr>      </table>    </div>           <br><br>    <div class="section">        <table class="content-table" style="width:100%">          <tr class="main-content-table-row">            <th class ="section-heading">Introduction</th>          </tr>          <!--- INTRODUCTION -->          <tr class="main-content-table-row">            <td class="section-content-table-data" valign="top">              <ul>                <li>The visualization of multidimensional spatiotemporal data presents a challenging representational problem that often overlooks the strengths of the multiple sensory channels of the human perceptual system</li>                <li>Our interest in sonifying these data stems from our research into the use of computational fluid dynamics (CFD) for predicting cerebral aneurysm rupture </li>                <li>We aim to use sonification to better understand the nature of turbulent-like instabilities in our data which may have clinical relevance</li>                <li>Previous work has focused on developing algorithms and aesthetics but did not robustly consider how the resultant sounds were being perceived to make sense of these complex flows</li>                <li>The goal of this work is to apply ideas from auditory perception to create new sonifications that allow for better classification of flow phenotypes than before</li>              </ul>              <h3 align="center">Previous work</h3>              <p align="center"><a href = "https://smartech.gatech.edu/handle/1853/58365", target="_blank">ICAD 2017</a>&nbsp &nbsp &nbsp &nbsp<a href = "https://smartech.gatech.edu/handle/1853/60063", target="_blank">ICAD 2018</a></p>              <p align="center">                  <img class="myBtn_multi vid" src="media/richard-graphic.png" alt="2017 video sonification" width=15%>                  <img class="myBtn_multi vid" src="media/dan-graphic.png" alt="2018 spectral sonification" width=15%>              </p>                <div class="modal modal_multi">                    <div class="modal-content">                        <span class="close close_multi">×</span>                        <h2>2017 - Video sonification</h2>                        <p>Video sonification was too dependent on subjective rendering choices such as camera positions, and spatial relationships were lost.</p>                        <br>                        <p align="center"> <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/uifvp1S-WKU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                    </div>                </div>                <div class="modal modal_multi">                    <div class="modal-content">                        <span class="close close_multi">×</span>                        <h2>2018 - Spectral analysis-resynthesis</h2>                        <p>This technique synthesized spectrograms of velocity-time data using estabished spectral analysis resynthesis techniques, analogous to a phase vocoder. It was difficult to pick out certain features in the data such as the presence of spectral harmonics. There was also insufficient temporal variation present in the sounds to communicate the presence of quasi-random fluctuations in the flow. Sounds were too similar within and/or betwen models.</p>                        <br>                        <p align="center"><iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/UmDvnPjnpV4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                    </div>                </div>            </td>        </table>    </div>    <br><br>    <div class="section">        <table class="content-table" style="width:100%">          <tr class="main-content-table-row">            <th class ="section-heading" style="border-radius: 25px; border-right: 3px solid  #ff8080;">Methods</th>             <th class ="section-heading">Results</th>          </tr>            <!---  METHODS -->                    <td class="section-content-table-data" valign="top" style="border-right: 3px solid  #ff8080; border-radius: 25px;">              <ul>                <li>We took a feature-based approach, guided by the analogy of <a href = "http://pages.cs.wisc.edu/~dyer/ah336/papers/ramachandran-science-art.pdf", target="_blank">"caricature"</a>, sonifying unique features along perceptually distinct streams, informed by <a href="https://mitpress.mit.edu/books/auditory-scene-analysis" target="_blank">auditory scene analysis</a> </li>                <li>We begin by computing <a href="https://doi.org/10.1080/21681163.2019.1647461", target="blank"> Q-criterion</a> (vortex cores) and the average velocity <a href="https://doi.org/10.1016/j.jbiomech.2020.109977" target="_blank">spectrogram</a> in an aneurysm sac</li>                <li>Spectral features and motion from 2D Q-criterion projections are algorithmically extracted are sonified using ecological instrument models</li>              </ul>              <p align="center"><img src="media/figure3-transparant.png" alt="Methods" usemap="#methodsmap" border=0 width="100%" height="auto" class="map"></p>                  <map name="methodsmap" id=Map>                  <area class="myBtn_multi" target="" alt="cfd-data" title="cfd-data" href="#" coords="68,1080,884,172" shape="rect">                  <area class="myBtn_multi" target="" alt="harmonics" title="harmonics" href="#" coords="1040,108,1453,465" shape="rect">                  <area class="myBtn_multi" target="" alt="envelope" title="envelope" href="#" coords="1467,475,1038,805" shape="rect">                  <area class="myBtn_multi" target="" alt="projection" title="projection" href="#" coords="1020,814,1495,1098" shape="rect">                  <area class="myBtn_multi" target="" alt="tonal" title="tonal" href="#" coords="2020,541,1587,172" shape="rect">                  <area class="myBtn_multi" target="" alt="buffeting" title="buffeting" href="#" coords="2022,611,1575,1088" shape="rect">                  <area class="myBtn_multi" target="" alt="output" title="output" href="#" coords="2048,441,2266,695" shape="rect">              </map>              <!-- CFD DATA MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>CFD data</h2>                      <p>We begin by computing the average spectrogram and Q-criterion in an aneurysm sac. The spectrogram acts as a sort of "global" indicator of flow instability, and the Q-criterion communicates more localized spatiotemporal fluctuations.                      <p align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/BmHwz3CB3TI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                  </div>              </div>              <!-- HARMONIC FEATURES MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>Spectral harmonics feature</h2>                      <p>Spectral harmonics can be associated with vortex shedding flow patterns. We extract them by finding local maxima in column-wise traces of power alone the spectrogram's time axis. These bands are extracted and labelled depending on their temporal occurrence such that simultaneous harmonics are grouped together.</p>                      <p align="center"><img src="media/spectrogram.png" width = 40% height ="auto"><img src="media/harmonics.gif" width=40% height="auto"></p>                  </div>              </div>              <!-- ENVELOPE FEATURES MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>Spectral envelope feature</h2>                      <p>The envelope feature is extracted by first finding, at each time point, the largest frequency bin above a heuristic threshold.</p>                      <p align="center"><img src="media/envelope.gif" width=50% height="auto"></p>                  </div>              </div>                                                 <!-- PROJECTION MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>2D Motion projection</h2>                      <p>The aneurysm sac and its Q-criterion isosurfaces are flattened in the direction normal to the aneurysm's ostium.</p>                      <p align="center"> <img src="media/squish.gif" width=70% height=auto></p>                      <p>The strength and location of vortical structures are approximated by casting out 16 rays spaced at equal angles from the flattened plante's centre. Along each line we extract the average magnitude of Q-criterion and the location of the center of intersecting structures.</p>                      <p align="center"> <img src="media/flatmotion.gif" width=70% height=auto></p>                      <br><br><br><br><br><br>                  </div>              </div>              <!-- TONAL INSTRUMENT MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>Tonal instrument</h2>                      <p>An overtone rich sawtooth synth is used to sonify each harmonic band such that vertically stacked bands will be mpaped to successive notes in a major chord. This is purely an aesthetic choice, no musical vocablary/knowledge should be needed to interpret these sounds.</p>                      <h3 align="center">Listen to the isolated instrument below</h3>                      <p align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/aGSSuubsGU4" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                  </div>              </div>              <!-- BUFFETING INSTRUMENT MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>FM synthesis instrument model</h2>                      <p>The strength of vortical structures and their distance to the centre of the sac are used to modulate a noisy synth model that is designed to bear sound-source similarity to turbulent fluids, changing in its "buffeting" rate as more rapidly fluctuating structures are passed into it. The spectral envelope is added, proportionally controlling the cutoff of a additional instrument model. </p>                      <p align="center"> <img src="media/figure6.png" width=50% height=auto></p>                      <br>                      <h3 align="center">Listen to the isolated instrument below</h3>                      <p align="center"><iframe width="560" height="315" src="https://www.youtube.com/embed/1IBbFwinW5I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                      <br><br><br><br><br><br><br>                  </div>              </div>              <!-- OUTPUT AUDIO MODAL -->              <div class="modal modal_multi">                  <div class="modal-content">                      <span class="close close_multi">×</span>                      <h2>Output visualization with sonification</h2>                      <p>The tonal and buffeting sounds are mixed together and syncronized with their corresponding visualization.</p>                      <p align="center"><iframe  class="yt" width="560" height="315" src="https://www.youtube.com/embed/Lq1EBxjr2GI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></p>                  </div>              </div>            </td>            <!--- RESULTS -->                    <td class="section-content-table-data" valign=top>              <ul>                <li>In general, the current sonification allows for better detection of broadband and harmonic spectral features, as well as improved identification of finer-scale spatiotemporal fluctuations in the data</li>              </ul>              <p align="center"><img class="myBtn_multi vid" src="media/results_pic.png" alt="Results" width=80%></p>                <div class="modal modal_multi">                    <div class="modal-content">                        <span class="close close_multi">×</span>                        <h2>Results</h2>                        <br>                        <p>The videos and text below will walk through the different classifications that can be made using these sonifications. </p>                        <table>                          <tr>                            <th>"Laminiar" vs. "Unstable" flow</th>                          </tr>                          <tr>                            <td>Comparing the global evolution of a flow's sonic characteristics allows for this classification to be made with relative ease based on everyday listening experiences. Laminar flows (the first video below) will sound like a quick pulse with no noisy components. This is contrasted with "turbulent" flows (the second video below) which are synthesized to sound more noisy and buffeting. </td>                          </tr>                          <tr>                            <td>                              <p align="center"><iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/YMyc3xbVkws" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                              <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/Lq1EBxjr2GI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> </p>                                                        </td>                          </tr>                          <tr>                            <th>"Chaotic turbulence" vs. "Vortex shedding" </th>                          </tr>                          <tr>                            <td>Detecting the presence of harmonic featres in the sonifications can help the listener to identify whether instabilities in the flow visualizations are a result of pure "turbulence" or more pure periodic vortex shedding. The first case shows "chaotic turbulence" as we cannot hear any tonal sounds. In the second case, we can hear tonal sounds (listen for the whistling sound) which indicate the presence of spectral harmonics. When we map the presence/absence of this sound back to the visualization, we can reinforce the observation that the vortical structures in the first case appear to be far less coherent (i.e., are moving around much more randomly) than those in the second which are being periodically shed just pas the aneurysm's neck.</td>                          </tr>                          <tr>                            <td>                              <p align="center">                                  <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/1NpMiylOZ8I" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                                  <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/Lq1EBxjr2GI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                              </p>                                                        </td>                          </tr>                                                    <th>Differences in quasi-random fluctuations</th>                          </tr>                          <tr>                            <td>The spectrograms for either case below are similar with respect to their envelope and harmonic features. Either case, however, seems to have quite different flow patterns. When we listen to the buffeting sounds generated in either case, this difference becomes highlighted. In the first case, we see a major large core form in the centre of the sac which appears to fluctuate and rotate in place. In the second case, as has been mentioned, we see coherent structures being shed from around the neck of the aneurysm. These differences in motion are sonically captured by the buffeting sounds generated in either case. In the first case, the periodicity of the buffeting sound seems to sync with the periodicity of the central core's rotation/fluctuation. In the second case, the periodicity of the buffeting sound seems to sync with the frequency of the shed vortices.</td>                          </tr>                          <tr>                            <td>                              <p align="center">                                                                    <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/lWqGOzN7Lio" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                                  <iframe class="yt" width="560" height="315" src="https://www.youtube.com/embed/Lq1EBxjr2GI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>                              </p>                                                        </td>                          </tr>                            </table>                        <br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>                    </div>                </div>            </td>          </tr>        </table>    </div>    <br><br>    <div class="section">        <table class="content-table" style="width:100%">          <tr class="main-content-table-row">            <th class ="section-heading" style="border-right: 3px solid  #ff8080; border-radius: 25px;">Discussion</th>            <th class ="section-heading">Future directions</th>           </tr>          <tr>            <td class="section-content-table-data" valign="top" style="border-right: 3px solid  #ff8080; border-radius: 25px;">              <ul>                <li>Our "carictured" approach allows for characteristic features to be interpreted quickly, while minimizing those features that are common between models</li>                <li>There seems to be a redundancy gain when congruency and/or causality is maintained between visualizations and sonifications</li>                <li>The apparant timbral differences allow for the primitive scene analysis system to partition the soifications allowing for information about features to be accessed with minimal interference</li>                <li>The buffeting instrument model allows for interpretation of the behavior of "turbulence" in these flows as more chaotic flows create more noisy buffeting sounds, in line with fluidic sounds that we experience in everyday listening environments</li>                <li>The tonal sounds can be associated with vibration/resonance (e.g., a stringed instrument or whistling wind). Similar tonal bruits have been observed in in vivo aneurysms, which we hypothesize to be associated with spectral harmonics</li>              </ul>            </td>            <td class="section-content-table-data" valign="top">              <ul>                <li>We have removed interactivity from our sonification pipeline for now in order to focus more on the perception of generated sounds. This could be reintegrated in the future if it is viable in clinical workflows</li>                <li>We have begun to observe existing cross-sensory intuitions between Q-criterion visualziations and sounds when presented to our clinical collaborator. In general some clinical users are familiar with making sense of relationships between blood flows and sound through cardiac auscultation</li>                <li>Future studies should elicit these existing intuitions and incorporate them into the design of sonifications and aim to more formally validation some of the theoretical speculations presented here</li>                <li>Ultimately, future user studies should aim to test the efficacy of these bimodal representations in clinical workflows</li>              </ul>            </td>          </tr>        </table>  </div>  <br>  <p align="center"><a href="mailto:lucas.temor@mail.utoronto.ca"><img class="vid" style="box-shadow: none;" src="media/email.png" width="5%" height="auto"></p></a>  <br><br><br><br><br><br><br><br>    <script>      window.addEventListener('resize', function () {           "use strict";          window.location.reload();       });    </script>          <script src="js/modal.js"></script>    <script type="text/javascript" src="https://code.jquery.com/jquery-3.3.1.min.js"></script>    <script type="text/javascript" src="js/maphilight-master/jquery.maphilight.min.js"></script>    <script type="text/javascript" src="js/image-map-resizer-master/js/imageMapResizer.min.js"></script>    <script type="text/javascript">$(function() {        $('.map').maphilight();         });    </script>    <script type="text/javascript">    $('map').imageMapResize();    </script>    <script>      $('map').click(function(event)      {        event.preventDefault();      });    </script>  </body></html>